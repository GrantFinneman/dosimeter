{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction notebook\n",
    "\n",
    "This notebook will be used to extract the data from the ohio runs and potentially the data generated by geant\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ohio Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from my_classes import load_data_ohio\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n",
    "from my_classes import *\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates a list of file paths of the original ohio data\n",
    "- Does not add the file to the list if help or 22 is in the name since help.txt is not a data file and run 22 is garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = 'ohio_data/runs/'\n",
    "run_paths = [os.path.join(run_path, file) for file in os.listdir(run_path)\n",
    "             if all(('help' not in file, '22' not in file, file.endswith('.txt')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates a dictionary holding each file and the energy deposition of each channel\n",
    "\n",
    "- Some values are negative which doesn't make sense in this context since they are measureing light exposure through coulombs. Because of the random negative values I translate everything up by the magnitude of the most negative number (subtract the most negative number from everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_edeps = {}\n",
    "for file_path in run_paths:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    df = pd.read_csv(file_path, delimiter='\\t', skiprows=19)\n",
    "    overall_min = df[5:-2].min().min() # Needs to be done twice dince the first one gives [1, 64] array of minimums of each column\n",
    "    \n",
    "    channel_edep = {}\n",
    "    for col in df.columns[5:-2]:\n",
    "        channel_edep[col] = sum(df[col] + abs(overall_min))\n",
    "    \n",
    "    file_edeps[file_name] = channel_edep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves the channel and the corresponding energy deposition in a file with the same name as the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_edeps:\n",
    "    with open(f'ohio_data/extracted_data/{file}', 'w') as fhandle:\n",
    "        print(f'''This file was gnenerated on {str(datetime.today())} by Grant Finneman. This contains the data colleted by\\nAlex in Ohio. The only processing that has been done so far is summing the edep of each channel.''', file=fhandle)\n",
    "        print('Channel edep', file=fhandle)\n",
    "        \n",
    "        for channel, edep in file_edeps[file].items():\n",
    "            print(f\"{channel.replace(' ',''):5s} {edep:.5f}\", file=fhandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gate Simulation Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_dir = 'gate_simulations/bar_simulation/output/'\n",
    "\n",
    "# globbing to find all files that end in Hits.dat\n",
    "paths = sorted(glob(f'{hit_dir}*Hits.dat'))\n",
    "\n",
    "# generates the correct names for the columns I want\n",
    "names = [f'col{num}' for num in range(1, 24)]\n",
    "names[7] = 'id'\n",
    "names[8] = 'edep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    f_name = os.path.basename(path).rstrip('Hits.dat')\n",
    "\n",
    "    # Initializes the dictionary with keys from 0-63 and values of 0\n",
    "    file_edep = dict.fromkeys(list(range(64)), 0)\n",
    "\n",
    "    # Loads the data from the current Hits file\n",
    "    df = pd.read_csv(path, delim_whitespace=True, names=names)\n",
    "\n",
    "    for id_num, edep in zip(df['id'], df['edep']):\n",
    "        file_edep[id_num] += edep\n",
    "\n",
    "    with open(f'gate_data/bars/{f_name}extracted.txt', 'w') as fhandle:\n",
    "        print(f'This file was gnenerated on {str(datetime.today())} by Grant Finneman. This contains the extracted data from the Gate simulations\\nThe edep for each bar was summed up and printed to this file. The only math operation done has been addition.\\n', file=fhandle)\n",
    "        print(tabulate(file_edep.items(), headers=['id', 'edep'], showindex=False, tablefmt='plain'), file=fhandle)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterates over all of the paths in the paths list and loads the data into a dataframe from pandas. I made a list of column names above and give that to pandas. Using the ability to access columns in pandas I iterate over the ID and edep columns and keep a running total of the edep for each bar with a dictionary. Still within the paths loop, I open a file and give it the same name as the original file using fstrings makes this easy. I print bar_id edep as column headers then print the individual rows with a or loop to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cube Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_dir = 'gate_simulations/cube_simulation/output/'\n",
    "\n",
    "# globbing to find all files that end in Hits.dat\n",
    "paths = sorted(glob(f'{hit_dir}*Hits.dat'))\n",
    "\n",
    "# generates the correct names for the columns I want\n",
    "names = [f'col{num}' for num in range(1, 24)]\n",
    "names[7] = 'id'\n",
    "names[8] = 'edep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    f_name = os.path.basename(path).rstrip('Hits.dat')\n",
    "\n",
    "    # Initializes the dictionary with keys from 0-63 and values of 0\n",
    "    file_edep = dict.fromkeys(list(range(512)), 0)\n",
    "\n",
    "    # Loads the data from the current Hits file\n",
    "    df = pd.read_csv(path, delim_whitespace=True, names=names)\n",
    "\n",
    "    for id_num, edep in zip(df['id'], df['edep']):\n",
    "        file_edep[id_num] += edep\n",
    "\n",
    "    with open(f'gate_data/cubes/{f_name}extracted.txt', 'w') as fhandle:\n",
    "        print(f'This file was gnenerated on {str(datetime.today())} by Grant Finneman. This contains the extracted data from the Gate simulations\\nThe edep for each cube was summed up and printed to this file. The only math operation done has been addition.\\n', file=fhandle)\n",
    "        print(tabulate(file_edep.items(), headers=['id', 'edep'], showindex=False, tablefmt='plain'), file=fhandle)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geant Processing\n",
    "**This section is now obsolete and not needed but here for illustration purposes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generating list of cube and bar files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data_dir = 'geant_data/dosimeterDataMMRotated_Completed_1_19_2020/'\n",
    "filenames = sorted([os.path.join(data_dir, file) for file in os.listdir(data_dir)\n",
    "            if all(('Training' not in file, 'All' not in file, file.endswith('.txt')))])\n",
    "\n",
    "cube_filenames = [path for path in filenames if 'Cube' in path]\n",
    "bar_filenames = [path for path in filenames if 'Bars' in path]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generates dictionaries of bar files with edep array, cube files and edep array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "cube_edeps = {}\n",
    "for path in cube_filenames:\n",
    "    filename = os.path.basename(path)\n",
    "    df = pd.read_csv(path, delim_whitespace=True, names=['x_dim', 'y_dim', 'z_dim', 'edep'])\n",
    "    cube_edeps[filename] = list(df['edep'])\n",
    "    \n",
    "bar_edeps = {}\n",
    "for path in bar_filenames:\n",
    "    filename = os.path.basename(path)\n",
    "    df = pd.read_csv(path, delim_whitespace=True, names=['x_dim', 'y_dim', 'z_dim', 'edep'])\n",
    "    bar_edeps[filename] = list(df['edep'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Writes the bar edep and cube edep to their extraction files\n",
    "- Not much processing is required here since there are no weird values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "extracted_cubes = 'geant_data/extracted_data/cubes/'\n",
    "\n",
    "for filename, data in cube_edeps.items():\n",
    "    new_name = f'{filename.rstrip(\".txt\")}_extracted.txt'\n",
    "    with open(os.path.join(extracted_cubes, new_name), 'w') as file:\n",
    "        print('cubeID edep', file=file)\n",
    "        for ID, edep in enumerate(data):\n",
    "            print(f'{ID} {edep:.5f}', file=file)\n",
    "            \n",
    "extracted_bars = 'geant_data/extracted_data/bars/'\n",
    "\n",
    "for filename, data in bar_edeps.items():\n",
    "    new_name = f'{filename.rstrip(\".txt\")}_extracted.txt'\n",
    "    with open(os.path.join(extracted_bars, new_name), 'w') as file:\n",
    "        print('barID edep', file=file)\n",
    "        for ID, edep in enumerate(data):\n",
    "            print(f'{ID} {edep:.5f}', file=file)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-james]",
   "language": "python",
   "name": "conda-env-.conda-james-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
