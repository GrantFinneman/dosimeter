{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction notebook\n",
    "\n",
    "This notebook will be used to extract the data from the ohio runs and potentially the data generated by geant\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from my_classes import load_data_ohio\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n",
    "from my_classes import *\n",
    "from glob import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ohio Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates a list of file paths of the original ohio data\n",
    "- Does not add the file to the list if help or 22 is in the name since help.txt is not a data file and run 22 is garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = 'ohio_data/runs/'\n",
    "\n",
    "# List of filenames that end in .txt except files that contain 'help' and '22'\n",
    "run_paths = [os.path.join(run_path, file) for file in os.listdir(run_path)\n",
    "             if all(('help' not in file, '22' not in file, file.endswith('.txt')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates a dictionary holding each file and the energy deposition of each channel\n",
    "\n",
    "- Some values are negative which doesn't make sense in this context since they are measureing light exposure through coulombs. Because of the random negative values I translate everything up by the magnitude of the most negative number (subtract the most negative number from everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_edeps = {}\n",
    "for file_path in run_paths:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    df = pd.read_csv(file_path, delimiter='\\t', skiprows=19)\n",
    "    overall_min = df[5:-2].min().min() # Needs to be done twice since the first one gives [1, 64] array of minimums of each column\n",
    "    \n",
    "    channel_edep = {}\n",
    "    for col in df.columns[5:-2]:\n",
    "        channel_edep[col] = sum(df[col] + abs(overall_min))\n",
    "    \n",
    "    file_edeps[file_name] = channel_edep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves the channel and the corresponding energy deposition in a file with the same name as the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_edeps:\n",
    "    with open(f'ohio_data/extracted_data/{file}', 'w') as fhandle:\n",
    "        print(f'''This file was gnenerated on {str(datetime.today())} by Grant Finneman. This contains the data colleted by\\nAlex in Ohio. The only processing that has been done so far is summing the edep of each channel.''', file=fhandle)\n",
    "        print('Channel edep', file=fhandle)\n",
    "        \n",
    "        for channel, edep in file_edeps[file].items():\n",
    "            print(f\"{channel.replace(' ',''):5s} {edep:.5f}\", file=fhandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gate Simulation Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generalized the simulation extraction to an arbitrary number of volumes of the simulation so I could use a single function on both cube and bar simulations. It takes in a list of data files ready for extraction. It will iterate through them and use pandas to parse the text files. Since they both have volumes starting at number $0$ I don't need to pre-define the size of the dictionary. I use a dictionary since it's pretty easy to use them for keeping running totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processGateVolumes(hit_paths, output_dir):\n",
    "    '''This function takes in a list of paths that point to the \n",
    "    output files of the Gate simulation to be processed.\n",
    "    The files containing the data should all\n",
    "    have the ending Hits.dat.\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    hit_paths : [list] A list of paths to the hits.dat files to be processed\n",
    "    \n",
    "    output_dir : [str] Path pointing to the direcotry where the extracted files will be placed\n",
    "    this should not end with a '/'\n",
    "    '''\n",
    "\n",
    "    # Generates the correct names for the columns in the file\n",
    "    names = [f'col{num}' for num in range(1, 24)]\n",
    "    names[7] = 'id'\n",
    "    names[8] = 'edep'\n",
    "\n",
    "    for path in hit_paths:\n",
    "        # Removes the suffix 'Hits.dat' from the filename for use in the output file\n",
    "        f_name = os.path.basename(path).rstrip('Hits.dat')\n",
    "        \n",
    "        # Loads the data from the current Hits file\n",
    "        df = pd.read_csv(path, delim_whitespace=True, names=names)\n",
    "        \n",
    "        # Defaultdect returns 0 for each key that doesn't exist\n",
    "        # allows a running total to be easily calculated by +=\n",
    "        volume_edep = defaultdict(int)\n",
    "        \n",
    "        for id_num, edep in sorted(zip(df['id'], df['edep'])):\n",
    "            volume_edep[id_num] += edep\n",
    "            \n",
    "        with open(f'{output_dir}/{f_name}extracted.txt', 'w') as fhandle:\n",
    "            print(f'This file was gnenerated on {str(datetime.today())} by Grant Finneman. This contains the extracted data from the Gate simulations\\nThe edep for each bar was summed up and printed to this file. The only math operation done has been addition.\\n', file=fhandle)\n",
    "            print(tabulate(volume_edep.items(), headers=['id', 'edep'], showindex=False, tablefmt='plain'), file=fhandle)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hit_dir = 'gate_simulations/bar_simulation/output/'\n",
    "\n",
    "# Globbing to find all files that end in Hits.dat\n",
    "bar_paths = sorted(glob(f'{hit_dir}*Hits.dat'))\n",
    "processGateVolumes(hit_paths=bar_paths, output_dir='gate_data/bars/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cube Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_dir = 'gate_simulations/cube_simulation/output/'\n",
    "\n",
    "# Globbing to find all files that end in Hits.dat\n",
    "cube_paths = sorted(glob(f'{hit_dir}*Hits.dat'))\n",
    "processGateVolumes(hit_paths=cube_paths, output_dir='gate_data/cubes/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geant Processing\n",
    "**This section is now obsolete and not needed but here for illustration purposes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generating list of cube and bar files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "data_dir = 'geant_data/dosimeterDataMMRotated_Completed_1_19_2020/'\n",
    "filenames = sorted([os.path.join(data_dir, file) for file in os.listdir(data_dir)\n",
    "            if all(('Training' not in file, 'All' not in file, file.endswith('.txt')))])\n",
    "\n",
    "cube_filenames = [path for path in filenames if 'Cube' in path]\n",
    "bar_filenames = [path for path in filenames if 'Bars' in path]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generates dictionaries of bar files with edep array, cube files and edep array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "cube_edeps = {}\n",
    "for path in cube_filenames:\n",
    "    filename = os.path.basename(path)\n",
    "    df = pd.read_csv(path, delim_whitespace=True, names=['x_dim', 'y_dim', 'z_dim', 'edep'])\n",
    "    cube_edeps[filename] = list(df['edep'])\n",
    "    \n",
    "bar_edeps = {}\n",
    "for path in bar_filenames:\n",
    "    filename = os.path.basename(path)\n",
    "    df = pd.read_csv(path, delim_whitespace=True, names=['x_dim', 'y_dim', 'z_dim', 'edep'])\n",
    "    bar_edeps[filename] = list(df['edep'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Writes the bar edep and cube edep to their extraction files\n",
    "- Not much processing is required here since there are no weird values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "extracted_cubes = 'geant_data/extracted_data/cubes/'\n",
    "\n",
    "for filename, data in cube_edeps.items():\n",
    "    new_name = f'{filename.rstrip(\".txt\")}_extracted.txt'\n",
    "    with open(os.path.join(extracted_cubes, new_name), 'w') as file:\n",
    "        print('cubeID edep', file=file)\n",
    "        for ID, edep in enumerate(data):\n",
    "            print(f'{ID} {edep:.5f}', file=file)\n",
    "            \n",
    "extracted_bars = 'geant_data/extracted_data/bars/'\n",
    "\n",
    "for filename, data in bar_edeps.items():\n",
    "    new_name = f'{filename.rstrip(\".txt\")}_extracted.txt'\n",
    "    with open(os.path.join(extracted_bars, new_name), 'w') as file:\n",
    "        print('barID edep', file=file)\n",
    "        for ID, edep in enumerate(data):\n",
    "            print(f'{ID} {edep:.5f}', file=file)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-james]",
   "language": "python",
   "name": "conda-env-.conda-james-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
